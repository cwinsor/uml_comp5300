{"cells":[{"cell_type":"code","source":["# for source code we use git - clone the repo\n","# remember, like any colab, you need to persist changes before leaving\n","# i.e. git commit and push i\n","! git clone https://github.com/cwinsor/uml_comp5300.git\n","# add to PYTHONPATH so our code can be found\n","# we squirrel a copy of the original in case the block gets re-run\n","import os\n","my_code = \"/content/uml_comp5300/hw6_translation\"\n","if \"ORIGINAL_PYTHONPATH\" not in os.environ:\n","    os.environ['ORIGINAL_PYTHONPATH'] = os.environ['PYTHONPATH']\n","os.environ['PYTHONPATH'] = os.environ['ORIGINAL_PYTHONPATH']\n","os.environ['PYTHONPATH'] += \":\" + my_code\n","os.environ['PYTHONPATH'] += \":\" + my_code + \"/transformer_mt\"\n","print(f\"PYTHONPATH={os.environ['PYTHONPATH']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dyMcXEfGRCUz","executionInfo":{"status":"ok","timestamp":1679590326500,"user_tz":240,"elapsed":315,"user":{"displayName":"Chris Winsor","userId":"06032669675435120814"}},"outputId":"2b0598d8-d06f-4b3e-8411-01d34ac127d0"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'uml_comp5300' already exists and is not an empty directory.\n","PYTHONPATH=/env/python:/content/uml_comp5300/hw6_translation:/content/uml_comp5300/hw6_translation/transformer_mt\n"]}]},{"cell_type":"code","source":["# for data we use google drive - this is transformers and model parameters\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"14e_UiHUQoe1","executionInfo":{"status":"ok","timestamp":1679589419340,"user_tz":240,"elapsed":1743,"user":{"displayName":"Chris Winsor","userId":"06032669675435120814"}},"outputId":"4747b97e-2f98-4fc1-97a0-85fb79b416c0"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# this notebook has library requirements ... add them here.\n","with open(my_code + \"requirements.txt\") as f:\n","    install_requires = f.read()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4nhHoFKKM_7F","executionInfo":{"status":"ok","timestamp":1679589853389,"user_tz":240,"elapsed":16,"user":{"displayName":"Chris Winsor","userId":"06032669675435120814"}},"outputId":"6c8ec0b1-55b4-4399-e586-ce2be0d3f9c0"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["<_io.TextIOWrapper name='/content/uml_comp5300/hw6_translation/requirements.txt' mode='r' encoding='UTF-8'>\n"]}]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":338},"id":"DYt_pPymJgp6","executionInfo":{"status":"error","timestamp":1679590902981,"user_tz":240,"elapsed":311,"user":{"displayName":"Chris Winsor","userId":"06032669675435120814"}},"outputId":"d0e1c8e9-aeaf-4628-dfb3-4571ceb04cde"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-276fc8848b91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#from transformers import PreTrainedTokenizerFast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodeling_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransfomerEncoderDecoderModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'modeling_transformers'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["#from transformers import PreTrainedTokenizerFast\n","from modeling_transformers import TransfomerEncoderDecoderModel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DTFNS2fpJgqD"},"outputs":[],"source":["# You probably need to modify the paths to your tokenizers\n","# For tokenizers, you need to provide the path to a directory that contains the tokenizer.json file\n","# For model, you need to provide the path to a directory that contains the model.pt file\n","\n","source_tokenizer = PreTrainedTokenizerFast.from_pretrained(\"../output_dir/en_tokenizer\")\n","target_tokenizer = PreTrainedTokenizerFast.from_pretrained(\"../output_dir/es_tokenizer\")\n","\n","model = TransfomerEncoderDecoderModel.from_pretrained(\"../output_dir\")\n","model.eval();"]},{"cell_type":"markdown","metadata":{"id":"TOrNl8B_JgqF"},"source":["## Task\n","\n","Try out your model. Feel free to use your own sentences and to compare the model outputs to Google Translate.\n","Find at least three sentences that are translated well, and one that is translated badly.\n","\n","Feel free to change beam size and max_length parameters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hm16aTfrJgqL","outputId":"3ab452b0-c0b2-4077-e4e6-2daa8c2a6af2"},"outputs":[{"data":{"text/plain":["'Hello, my dog is sweet.'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["input_ids = source_tokenizer.encode(\"Hallo, mein Hund ist süß\", return_tensors=\"pt\")\n","output_ids = model.generate(\n","    input_ids,\n","    max_length=10,\n","    bos_token_id=target_tokenizer.bos_token_id,\n","    eos_token_id=target_tokenizer.eos_token_id,\n","    pad_token_id=target_tokenizer.pad_token_id,\n",")\n","target_tokenizer.decode(output_ids[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EJyutVeJJgqO"},"outputs":[],"source":[]}],"metadata":{"interpreter":{"hash":"f86d5ac646110a331c60478f9400a1a64d0cd523be90d887457228f9723636b5"},"kernelspec":{"display_name":"Python 3.7.11 ('nlp_class')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"},"orig_nbformat":4,"colab":{"provenance":[],"collapsed_sections":["TOrNl8B_JgqF"]}},"nbformat":4,"nbformat_minor":0}