{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformer_mt.modeling_transformer import TransfomerEncoderDecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../wandb/run-20230322_180023-jyra6nqi/files\\\\model_config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\code_uml\\uml_comp5300\\hw6_translation\\notebooks\\03_interact.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code_uml/uml_comp5300/hw6_translation/notebooks/03_interact.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m run_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../wandb/run-20230322_180023-jyra6nqi/files\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code_uml/uml_comp5300/hw6_translation/notebooks/03_interact.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# run_dir = \"../output_dir\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/code_uml/uml_comp5300/hw6_translation/notebooks/03_interact.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model \u001b[39m=\u001b[39m TransfomerEncoderDecoderModel\u001b[39m.\u001b[39;49mfrom_pretrained(run_dir)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code_uml/uml_comp5300/hw6_translation/notebooks/03_interact.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[1;32mG:\\My Drive\\code_uml\\uml_comp5300\\hw6_translation\\transformer_mt\\modeling_transformer.py:566\u001b[0m, in \u001b[0;36mTransfomerEncoderDecoderModel.from_pretrained\u001b[1;34m(cls, save_path, map_location)\u001b[0m\n\u001b[0;32m    563\u001b[0m \u001b[39mif\u001b[39;00m map_location \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m    564\u001b[0m     map_location \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 566\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(save_path, \u001b[39m\"\u001b[39;49m\u001b[39mmodel_config.json\u001b[39;49m\u001b[39m\"\u001b[39;49m), \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    567\u001b[0m     config \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m    569\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../wandb/run-20230322_180023-jyra6nqi/files\\\\model_config.json'"
     ]
    }
   ],
   "source": [
    "# You probably need to modify the paths to your tokenizers\n",
    "# For tokenizers, you need to provide the path to a directory that contains the tokenizer.json file\n",
    "# For model, you need to provide the path to a directory that contains the model.pt file\n",
    "\n",
    "source_tokenizer = PreTrainedTokenizerFast.from_pretrained(\"../output_dir/en_tokenizer\")\n",
    "target_tokenizer = PreTrainedTokenizerFast.from_pretrained(\"../output_dir/de_tokenizer\")\n",
    "\n",
    "run_dir = \"../wandb/run-20230322_180023-jyra6nqi/files\"\n",
    "# run_dir = \"../output_dir\"\n",
    "model = TransfomerEncoderDecoderModel.from_pretrained(run_dir)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "Try out your model. Feel free to use your own sentences and to compare the model outputs to Google Translate.\n",
    "Find at least three sentences that are translated well, and one that is translated badly.\n",
    "\n",
    "Feel free to change beam size and max_length parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Schließ symp, einzuhalten Arafat,, inspiriert Frattini lehnung'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = source_tokenizer.encode(\"Hallo, mein Hund ist süß\", return_tensors=\"pt\")\n",
    "output_ids = model.generate(\n",
    "    input_ids,\n",
    "    max_length=10,\n",
    "    bos_token_id=target_tokenizer.bos_token_id,\n",
    "    eos_token_id=target_tokenizer.eos_token_id,\n",
    "    pad_token_id=target_tokenizer.pad_token_id,\n",
    ")\n",
    "target_tokenizer.decode(output_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f86d5ac646110a331c60478f9400a1a64d0cd523be90d887457228f9723636b5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('nlp_class')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
